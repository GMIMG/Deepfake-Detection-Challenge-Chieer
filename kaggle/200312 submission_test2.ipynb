{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        # print(os.path.join(dirname, filename))\n",
    "        pass\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "!pip install '../input/dlibpkg/dlib-19.19.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install '../input/face-recognition/click-7.1.1-py2.py3-none-any.whl'\n",
    "#!pip install '/kaggle/input/face-recognition/Pillow-7.0.0-cp38-cp38-win32.whl'\n",
    "#!pip install '../input/needwheels/face_recognition_models-0.3.0-py2.py3-none-any.whl'\n",
    "#!pip install '../input/needwheels/face_recognition-1.3.0-py2.py3-none-any.whl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageChops, ImageEnhance, ImageDraw\n",
    "#import face_recognition\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = '../input/deepfake-detection-challenge/test_videos/'\n",
    "test_video_files = [test + x for x in sorted(os.listdir(test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs('../working/dataset/TEST')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_video_files = sorted(test_video_files)\n",
    "test_image_path = '../working/dataset/TEST/'\n",
    "test_image_files = [test_image_path + x for x in sorted(os.listdir(test_image_path))]\n",
    "\n",
    "test_videos = '../input/deepfake-detection-challenge/test_videos/'\n",
    "test_movie_files = [test_videos + x for x in sorted(os.listdir(test_videos))]\n",
    "\n",
    "dic = {i.split('/')[-1]:[0,0] for i in test_movie_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../input/kerasmodel5/e5.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "vid_num = 0\n",
    "all_vid = len(test_video_files)\n",
    "for vid in test_video_files:\n",
    "    count = 0\n",
    "    frame = 0\n",
    "    file_name_mp4 = vid.split('/')[-1]\n",
    "    file_name = file_name_mp4.split('.')[0]\n",
    "    cap = cv2.VideoCapture(vid)\n",
    "    while(cap.isOpened()):\n",
    "        ret = cap.grab()\n",
    "        if ret == False:\n",
    "            break\n",
    "        if frame % 30 == 0:\n",
    "            ret, image = cap.retrieve()\n",
    "            face_rects, scores, idx = detector.run(image, 0)\n",
    "            for i, d in enumerate(face_rects):\n",
    "                x1 = d.left()\n",
    "                y1 = d.top()\n",
    "                x2 = d.right()\n",
    "                y2 = d.bottom()\n",
    "                li = [x1,y1,x2,y2]\n",
    "                li = [0 if i<0 else li[idx] for idx, i in enumerate(li)]\n",
    "                x1,y1,x2,y2 = li\n",
    "                \n",
    "                crop_img = image[y1:y2, x1:x2]\n",
    "                pil = Image.fromarray(crop_img)\n",
    "                \n",
    "                #얼굴 윤곽선 따기\n",
    "                #landmarks = face_recognition.face_landmarks(crop_img)\n",
    "                #p = ImageDraw.Draw(pil)\n",
    "                #for idx, landmark in enumerate(landmarks):\n",
    "                #    for mark in landmark.keys():\n",
    "                #        p.line(landmark[mark], width=3)\n",
    "                \n",
    "                pix = np.array(cv2.resize(np.array(pil), (299, 299)))\n",
    "                pix = (pix.flatten() / 255.0).reshape(-1, 299, 299, 3)\n",
    "                \n",
    "                # dense 2일때\n",
    "#                 pred = model.predict(pix)[0]\n",
    "#                 filename = file_name+'.mp4'\n",
    "#                 dic[filename][0] += pred[1]\n",
    "                pred = model.predict(pix)[0][0]\n",
    "                filename = file_name+'.mp4'\n",
    "                dic[filename][0] += pred\n",
    "                dic[filename][1] += 1\n",
    "                count += 1\n",
    "        frame += 1\n",
    "    if vid_num%5 == 4:\n",
    "        print(dic[filename])\n",
    "        print(f'{vid_num}/{all_vid}')\n",
    "    vid_num += 1\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(dic, orient='index',columns=['real', 'num_img'])\n",
    "df.index.name='filename'\n",
    "df['label'] = (df['real']/df['num_img']).fillna(0.5) # 평균내기 # 얼굴 인식 못한 사진은 0.5로\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df[['label']]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[df2['label']==0] = 0.1\n",
    "df2.loc[df2['label']==1] = 0.9\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('submission.csv') # csv 저장"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
