{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"1_capture_train_img_link_origin_fake-MTCNN.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"YBKCrhE8mB9G","colab_type":"code","outputId":"e99df286-f4d0-4138-cd9e-eb4ce65368e8","executionInfo":{"status":"ok","timestamp":1584577992374,"user_tz":-540,"elapsed":7737,"user":{"displayName":"Jimin Hwang","photoUrl":"","userId":"11954576279429508826"}},"colab":{"base_uri":"https://localhost:8080/","height":688}},"source":["!pip install -U tensorflow-addons\n","!pip install -U tensorflow"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (0.8.3)\n","Requirement already satisfied, skipping upgrade: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons) (2.7.1)\n","Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.1.0)\n","Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.1)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n","Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n","Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.1.0)\n","Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n","Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.0)\n","Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n","Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n","Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n","Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.24.3)\n","Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n","Requirement already satisfied, skipping upgrade: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.1.1)\n","Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow) (45.2.0)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n","Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.7.2)\n","Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.21.0)\n","Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n","Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.2.1)\n","Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.0.0)\n","Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.8)\n","Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n","Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n","Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n","Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n","Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.3)\n","Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n","Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n","Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MWx67nU3OJLg","colab_type":"code","outputId":"7961a8d6-bcee-42a3-955e-604565b5399a","executionInfo":{"status":"ok","timestamp":1584578237274,"user_tz":-540,"elapsed":3999,"user":{"displayName":"Jimin Hwang","photoUrl":"","userId":"11954576279429508826"}},"colab":{"base_uri":"https://localhost:8080/","height":158}},"source":["!pip install -U keras"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n","Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n","Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n","Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n","Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.1)\n","Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z6e3_6P4iBAw","colab_type":"code","outputId":"9513eb07-407f-437c-a5f9-c950efd5171f","executionInfo":{"status":"ok","timestamp":1584578033846,"user_tz":-540,"elapsed":6702,"user":{"displayName":"Jimin Hwang","photoUrl":"","userId":"11954576279429508826"}},"colab":{"base_uri":"https://localhost:8080/","height":193}},"source":["!pip install mtcnn"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: mtcnn in /usr/local/lib/python3.6/dist-packages (0.1.0)\n","Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (2.2.5)\n","Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (4.1.2.30)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.0.8)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.1.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.18.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (2.8.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.12.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u5up_doZUl2D","colab_type":"code","outputId":"638fe780-1df3-424a-c5c7-2b7e6ecf0c68","executionInfo":{"status":"ok","timestamp":1584578272650,"user_tz":-540,"elapsed":10813,"user":{"displayName":"Jimin Hwang","photoUrl":"","userId":"11954576279429508826"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import cv2\n","import os\n","import json\n","import numpy as np\n","import pandas as pd\n","from PIL import Image, ImageChops, ImageEnhance, ImageDraw\n","from mtcnn import MTCNN"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"mSZvrJDKUsj2","colab_type":"code","outputId":"712ee338-8679-48d4-f9bf-50c74df4fc61","executionInfo":{"status":"ok","timestamp":1584578272652,"user_tz":-540,"elapsed":10020,"user":{"displayName":"Jimin Hwang","photoUrl":"","userId":"11954576279429508826"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive') # , force_remount=True"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_4Jh5-NEWvnf","colab_type":"code","outputId":"34a83dd8-89bc-4b62-e048-09c9631eb5c1","executionInfo":{"status":"ok","timestamp":1584578272654,"user_tz":-540,"elapsed":9250,"user":{"displayName":"Jimin Hwang","photoUrl":"","userId":"11954576279429508826"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import os\n","os.chdir('/content/drive/My Drive/kaggle/working')\n","print (os.getcwd())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/kaggle/working\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P90O31__Ul2h","colab_type":"code","outputId":"ccb2109b-edd4-4cb9-9a8e-b3f8094f5548","executionInfo":{"status":"ok","timestamp":1584578276708,"user_tz":-540,"elapsed":12867,"user":{"displayName":"Jimin Hwang","photoUrl":"","userId":"11954576279429508826"}},"colab":{"base_uri":"https://localhost:8080/","height":402}},"source":["train_sample_metadata = pd.read_json('../input/deepfake-detection-challenge/train_sample_videos/metadata.json').T\n","train_sample_metadata"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>split</th>\n","      <th>original</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>aagfhgtpmv.mp4</th>\n","      <td>FAKE</td>\n","      <td>train</td>\n","      <td>vudstovrck.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>aapnvogymq.mp4</th>\n","      <td>FAKE</td>\n","      <td>train</td>\n","      <td>jdubbvfswz.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>abarnvbtwb.mp4</th>\n","      <td>REAL</td>\n","      <td>train</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>abofeumbvv.mp4</th>\n","      <td>FAKE</td>\n","      <td>train</td>\n","      <td>atvmxvwyns.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>abqwwspghj.mp4</th>\n","      <td>FAKE</td>\n","      <td>train</td>\n","      <td>qzimuostzz.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>etejaapnxh.mp4</th>\n","      <td>FAKE</td>\n","      <td>train</td>\n","      <td>wtreibcmgm.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>etmcruaihe.mp4</th>\n","      <td>FAKE</td>\n","      <td>train</td>\n","      <td>afoovlsmtx.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>etohcvnzbj.mp4</th>\n","      <td>FAKE</td>\n","      <td>train</td>\n","      <td>bdnaqemxmr.mp4</td>\n","    </tr>\n","    <tr>\n","      <th>eudeqjhdfd.mp4</th>\n","      <td>REAL</td>\n","      <td>train</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>eukvucdetx.mp4</th>\n","      <td>FAKE</td>\n","      <td>train</td>\n","      <td>gjypopglvi.mp4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>400 rows × 3 columns</p>\n","</div>"],"text/plain":["               label  split        original\n","aagfhgtpmv.mp4  FAKE  train  vudstovrck.mp4\n","aapnvogymq.mp4  FAKE  train  jdubbvfswz.mp4\n","abarnvbtwb.mp4  REAL  train            None\n","abofeumbvv.mp4  FAKE  train  atvmxvwyns.mp4\n","abqwwspghj.mp4  FAKE  train  qzimuostzz.mp4\n","...              ...    ...             ...\n","etejaapnxh.mp4  FAKE  train  wtreibcmgm.mp4\n","etmcruaihe.mp4  FAKE  train  afoovlsmtx.mp4\n","etohcvnzbj.mp4  FAKE  train  bdnaqemxmr.mp4\n","eudeqjhdfd.mp4  REAL  train            None\n","eukvucdetx.mp4  FAKE  train  gjypopglvi.mp4\n","\n","[400 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"BECDOb89Ul25","colab_type":"code","colab":{}},"source":["# train 영상 path\n","train_sample = '../input/deepfake-detection-challenge/train_sample_videos/'\n","train_video_files = [train_sample + x for x in sorted(os.listdir(train_sample))]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hjfpSl3gUl3C","colab_type":"code","outputId":"fec07a25-22b4-4387-9960-aa5f255cb8fc","executionInfo":{"status":"ok","timestamp":1584578276716,"user_tz":-540,"elapsed":11784,"user":{"displayName":"Jimin Hwang","photoUrl":"","userId":"11954576279429508826"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_video_files.pop()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'../input/deepfake-detection-challenge/train_sample_videos/metadata.json'"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"svoNCSUrUl3K","colab_type":"code","colab":{}},"source":["# original이 있는 FAKE\n","train_sample_metadata['FAKE has original'] = [(train_sample_metadata.iloc[:,2][i] in list(train_sample_metadata.index)) for i in train_sample_metadata.T]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gvx1e59MUl3P","colab_type":"code","outputId":"9835952f-0cf0-459e-8bec-8a07d35177fa","executionInfo":{"status":"ok","timestamp":1584578276793,"user_tz":-540,"elapsed":10546,"user":{"displayName":"Jimin Hwang","photoUrl":"","userId":"11954576279429508826"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# original이 있는 FAKE 수\n","len(train_sample_metadata[train_sample_metadata['FAKE has original']]['original'])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["58"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"PgpGLzrgUl3U","colab_type":"code","outputId":"8e51d781-b9bf-47db-96cb-d10fd3cf4be8","executionInfo":{"status":"ok","timestamp":1584578276795,"user_tz":-540,"elapsed":9755,"user":{"displayName":"Jimin Hwang","photoUrl":"","userId":"11954576279429508826"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# FAKE가 있는 origin 수\n","len(train_sample_metadata[train_sample_metadata['FAKE has original']]['original'].unique())"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["42"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"ooAgSZ8zUl3Z","colab_type":"code","outputId":"5018acd7-f0bc-46ee-f8c3-2ea516b27388","executionInfo":{"status":"ok","timestamp":1584578276800,"user_tz":-540,"elapsed":9143,"user":{"displayName":"Jimin Hwang","photoUrl":"","userId":"11954576279429508826"}},"colab":{"base_uri":"https://localhost:8080/","height":228}},"source":["train_sample_metadata['original'].value_counts()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["atvmxvwyns.mp4    6\n","meawmsgiti.mp4    6\n","kgbkktcjxf.mp4    5\n","qeumxirsme.mp4    5\n","ywvlvpvroj.mp4    4\n","                 ..\n","fkyrrigzpt.mp4    1\n","tivkmbqgwp.mp4    1\n","bdnaqemxmr.mp4    1\n","qokxxuayqn.mp4    1\n","efwfxwwlbw.mp4    1\n","Name: original, Length: 209, dtype: int64"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"4oXFZPWXUl3d","colab_type":"code","outputId":"3380d422-d3f4-4bc4-d7a5-3fec29e86265","executionInfo":{"status":"ok","timestamp":1584578276821,"user_tz":-540,"elapsed":8597,"user":{"displayName":"Jimin Hwang","photoUrl":"","userId":"11954576279429508826"}},"colab":{"base_uri":"https://localhost:8080/","height":263}},"source":["# FAKE가 있는 origin 영상 리스트\n","original_vidio_has_fake = train_sample_metadata[train_sample_metadata['FAKE has original']]['original'].unique()\n","original_vidio_has_fake"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['atvmxvwyns.mp4', 'ccfoszqabv.mp4', 'dlpoieqvfb.mp4',\n","       'aytzyidmgs.mp4', 'dkuayagnmc.mp4', 'bzythlfnhq.mp4',\n","       'cppdvdejkc.mp4', 'bulkxhhknf.mp4', 'edyncaijwx.mp4',\n","       'dzyuwjkjui.mp4', 'efwfxwwlbw.mp4', 'cprhtltsjp.mp4',\n","       'djxdyjopjd.mp4', 'cpjxareypw.mp4', 'dbtbbhakdv.mp4',\n","       'ellavthztb.mp4', 'bxzakyopjf.mp4', 'cizlkenljw.mp4',\n","       'brwrlczjvi.mp4', 'drcyabprvt.mp4', 'crezycjqyk.mp4',\n","       'cyxlcuyznd.mp4', 'ekcrtigpab.mp4', 'ehtdtkmmli.mp4',\n","       'bwipwzzxxu.mp4', 'atkdltyyen.mp4', 'chtapglbcj.mp4',\n","       'caifxvsozs.mp4', 'bffwsjxghk.mp4', 'duycddgtrl.mp4',\n","       'ehccixxzoe.mp4', 'eckvhdusax.mp4', 'dakiztgtnw.mp4',\n","       'bgwmmujlmc.mp4', 'abarnvbtwb.mp4', 'bejhvclboh.mp4',\n","       'avmjormvsx.mp4', 'egghxjjmfg.mp4', 'dbnygxtwek.mp4',\n","       'cmbzllswnl.mp4', 'afoovlsmtx.mp4', 'bdnaqemxmr.mp4'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"4svbtAqAUl3j","colab_type":"code","colab":{}},"source":["# path\n","original_vidio_has_fake_path = '../input/deepfake-detection-challenge/train_sample_videos/' + original_vidio_has_fake"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eAgk7calUl3o","colab_type":"code","outputId":"1a7559dd-470d-4d15-d012-0e8934a0f4a6","executionInfo":{"status":"ok","timestamp":1584578276826,"user_tz":-540,"elapsed":7237,"user":{"displayName":"Jimin Hwang","photoUrl":"","userId":"11954576279429508826"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["# 0번 origin 영상으로 만든 fake 영상들 => 6개\n","train_sample_metadata[train_sample_metadata['original']==original_vidio_has_fake[0]].index"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['abofeumbvv.mp4', 'bqkdbcqjvb.mp4', 'cdyakrxkia.mp4', 'cycacemkmt.mp4',\n","       'czmqpxrqoh.mp4', 'dakqwktlbi.mp4'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"1lZ0bQH3Ul3s","colab_type":"code","colab":{}},"source":["# 경로 만들어주기 (kaggle kernel에서 필요)\n","try:\n","    os.makedirs('../working/dataset/FAKE3')\n","except:\n","    pass\n","try:\n","    os.makedirs('../working/dataset/REAL3')\n","except:\n","    pass"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pM7gXgzZUl3x","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZKag2e7hUl33","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"eNk7dmOOUl38","colab_type":"code","outputId":"064e98ed-cb3d-4524-9dd6-06766e016f64","executionInfo":{"status":"ok","timestamp":1584582027841,"user_tz":-540,"elapsed":281924,"user":{"displayName":"Jimin Hwang","photoUrl":"","userId":"11954576279429508826"}},"colab":{"base_uri":"https://localhost:8080/","height":756}},"source":["# origin 영상들로 학습시작\n","#detector = dlib.get_frontal_face_detector()\n","train_video_files = sorted(original_vidio_has_fake)\n","\n","#train_video_files = ['bdnaqemxmr.mp4']\n","mtcnn = MTCNN() # device='cuda:0',\n","\n","vid_num = 0\n","all_vid = len(train_video_files)\n","# origin 영상 얼굴찾기\n","for vid in train_video_files:\n","    count = 0\n","    path = '../input/deepfake-detection-challenge/train_sample_videos/' + vid\n","    file_name = vid.split('.')[0]\n","    face_coord = {}\n","    cap = cv2.VideoCapture(path)\n","    frame = 0\n","\n","    \n","    before_face_img_coord = []\n","    \n","    while(cap.isOpened()):\n","        ret = cap.grab()\n","        if ret == False:\n","            break\n","        #if frame % 30 == 0:\n","        ret, image = cap.retrieve()\n","        #img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        img = image\n","        face_coord[frame]=[]\n","        # 처음 얼굴이 나오면\n","        if not before_face_img_coord:\n","            faces = mtcnn.detect_faces(img)\n","            # 얼굴 한개 이상?\n","            for face_idx, face in enumerate(faces):\n","                if 'confidence' in face and face['confidence'] > 0.9:\n","                    x1,y1,w,h = face['box']\n","                    x2 = min(x1+w, img.shape[1])\n","                    y2 = min(y1+h, img.shape[0])\n","                    x1 = max(x1, 0)\n","                    y1 = max(y1, 0)\n","                    crop_img = img[y1:y2, x1:x2]\n","                    face_coord[frame].append([y1,y2,x1,x2])\n","\n","                    #plt.imshow(crop_img)\n","                    #plt.show()\n","                    cv2.imwrite(f'../working/dataset/REAL3/REAL_{file_name}_{frame}_{face_idx}.jpg', cv2.resize(crop_img, (299, 299)))\n","                    before_face_img_coord.append([y1,y2,x1,x2])\n","                    \n","                    break\n","                    \n","        # 이전에 검출된 face가 있으면\n","        else:\n","            for face_idx, coord in enumerate(before_face_img_coord):\n","                im = img[max(coord[0]-100,0) : min(coord[1]+100,img.shape[0]),\n","                         max(coord[2]-100,0) : min(coord[3]+100,img.shape[1])]\n","                face = mtcnn.detect_faces(im)\n","                if face:\n","                    # 1개만 저장해\n","                    x11,y11,w,h = face[0]['box']\n","                    x1 = max(max(coord[2]-100, 0) + x11, 0)\n","                    x2 = min(x1 + w, img.shape[1])\n","                    y1 = max(max(coord[0]-100, 0) + y11, 0)\n","                    y2 = min(y1 + h, img.shape[0])\n","                    crop_img2 = img[y1:y2, x1:x2]\n","                    \n","                    \n","                    face_coord[frame].append([y1,y2,x1,x2])\n","                    before_face_img_coord[face_idx]=[y1,y2,x1,x2]\n","                    \n","                    #plt.imshow(crop_img2)\n","                    #plt.show()\n","                    cv2.imwrite(f'../working/dataset/REAL3/REAL_{file_name}_{frame}_{face_idx}.jpg', cv2.resize(crop_img2, (299, 299)))\n","                    crop_img = crop_img2\n","                else:\n","                    face_coord[frame].append([y1,y2,x1,x2])\n","                    cv2.imwrite(f'../working/dataset/REAL3/REAL_{file_name}_{frame}_{face_idx}.jpg', cv2.resize(crop_img, (299, 299)))\n","\n","        frame += 1\n","    cap.release()\n","    \n","    # 이비디오의 fake 영상만큼 반복\n","    for fake_vid in train_sample_metadata[train_sample_metadata['original']==vid].index:\n","        fake_path = '../input/deepfake-detection-challenge/train_sample_videos/' + fake_vid\n","        cap2 = cv2.VideoCapture(fake_path)\n","        fake_vid_name = fake_vid.split('.')[0]\n","        frame2 = 0\n","        while(cap2.isOpened()):\n","            ret2 = cap2.grab()\n","            if ret2 == False:\n","                break\n","            #if frame2 % 30 == 0:\n","            ret2, image2 = cap2.retrieve()\n","            #img2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n","            for face_idx, i in enumerate(face_coord[frame2]):\n","                y1,y2,x1,x2 = i\n","                crop_img3 = image2[y1:y2, x1:x2]\n","                cv2.imwrite(f'../working/dataset/FAKE3/FAKE_{fake_vid_name}_{frame2}_{face_idx}_{file_name}.jpg', cv2.resize(crop_img3, (299, 299)))\n","            frame2 += 1\n","        cap2.release()\n","\n","        \n","    print(f'{vid_num}/{all_vid}')\n","    vid_num += 1\n","    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["0/42\n","1/42\n","2/42\n","3/42\n","4/42\n","5/42\n","6/42\n","7/42\n","8/42\n","9/42\n","10/42\n","11/42\n","12/42\n","13/42\n","14/42\n","15/42\n","16/42\n","17/42\n","18/42\n","19/42\n","20/42\n","21/42\n","22/42\n","23/42\n","24/42\n","25/42\n","26/42\n","27/42\n","28/42\n","29/42\n","30/42\n","31/42\n","32/42\n","33/42\n","34/42\n","35/42\n","36/42\n","37/42\n","38/42\n","39/42\n","40/42\n","41/42\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AuDxsSJ5JOuN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}