{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "!pip install '/kaggle/input/mtcnn-package/mtcnn-0.1.0-py3-none-any.whl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from PIL import Image, ImageChops, ImageEnhance, ImageDraw\n",
    "from mtcnn import MTCNN\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 영상 path\n",
    "test_video_path = '../input/deepfake-detection-challenge/test_videos/'\n",
    "test_videos_path = [test_video_path + x for x in sorted(os.listdir(test_video_path))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_model('../input/model2/deepfake-detection-model-ir7-2.h5')\n",
    "# model = load_model('../input/model3/chimacV8-09.h5')\n",
    "model = load_model('../input/model4/deepfake-detection2.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_num = 0\n",
    "all_vid = len(test_videos_path)\n",
    "filename = []\n",
    "label = []\n",
    "mtcnn = MTCNN()\n",
    "# origin 영상 얼굴찾기\n",
    "for vid_num, vid in enumerate(test_videos_path):\n",
    "    frame = 0\n",
    "    vid_name = vid.split('/')[-1]\n",
    "    pred = 0\n",
    "    detect_face_num = 0\n",
    "    before_face_img_coord = []\n",
    "    cap = cv2.VideoCapture(vid)\n",
    "    while(cap.isOpened()):\n",
    "        if frame == 5:\n",
    "            break\n",
    "        ret, img = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "\n",
    "            \n",
    "        if not before_face_img_coord:\n",
    "            face = mtcnn.detect_faces(img)\n",
    "            if not face:\n",
    "                frame += 1\n",
    "                continue\n",
    "            x1,y1,w,h = face[0]['box']\n",
    "            x2 = min(x1+w, img.shape[1])\n",
    "            y2 = min(y1+h, img.shape[0])\n",
    "            x1 = max(x1, 0)\n",
    "            y1 = max(y1, 0)\n",
    "            crop_img = img[y1:y2, x1:x2]\n",
    "            \n",
    "            \n",
    "            crop_img = cv2.resize(crop_img, (160, 160))\n",
    "            crop_img = (crop_img.flatten() / 255.0).reshape(-1, 160, 160, 3)\n",
    "            pred += model.predict(crop_img)[0][1]\n",
    "            \n",
    "            \n",
    "            before_face_img_coord = [y1,y2,x1,x2]\n",
    "            detect_face_num += 1\n",
    "\n",
    "        # 이전에 얼굴을 검출했으면 그주변에서 검색\n",
    "        else:\n",
    "            im = img[max(before_face_img_coord[0]-50,0) : min(before_face_img_coord[1]+50,img.shape[0]),\n",
    "                        max(before_face_img_coord[2]-50,0) : min(before_face_img_coord[3]+50,img.shape[1])]\n",
    "            face = mtcnn.detect_faces(im)\n",
    "            if face:\n",
    "                x11,y11,w,h = face[0]['box']\n",
    "                x1 = max(max(before_face_img_coord[2]-50, 0) + x11, 0)\n",
    "                x2 = min(x1 + w, img.shape[1])\n",
    "                y1 = max(max(before_face_img_coord[0]-50, 0) + y11, 0)\n",
    "                y2 = min(y1 + h, img.shape[0])\n",
    "                crop_img = img[y1:y2, x1:x2]\n",
    "                \n",
    "                \n",
    "                crop_img = cv2.resize(crop_img, (160, 160))\n",
    "                crop_img = (crop_img.flatten() / 255.0).reshape(-1, 160, 160, 3)\n",
    "                pred += model.predict(crop_img)[0][1]\n",
    "                \n",
    "                \n",
    "                before_face_img_coord = [y1,y2,x1,x2]\n",
    "                detect_face_num += 1\n",
    "        frame += 1\n",
    "\n",
    "    if before_face_img_coord:\n",
    "        acc = pred/detect_face_num\n",
    "        #acc = pred/300\n",
    "    else:\n",
    "        acc = 0.5\n",
    "        \n",
    "    filename.append(vid_name)\n",
    "    label.append(acc)\n",
    "    \n",
    "    print('*',end='')\n",
    "    if (vid_num+1) % 50 == 49:\n",
    "        print(vid_num,'/',all_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vid_num = 0\n",
    "# all_vid = len(test_videos_path)\n",
    "# filename = []\n",
    "# score = []\n",
    "# # origin 영상 얼굴찾기\n",
    "# for vid_num, vid in enumerate(test_videos_path):\n",
    "#     frame = 0\n",
    "#     vid_name = vid.split('/')[-1]\n",
    "#     before_face_img_coord = []\n",
    "#     cap = cv2.VideoCapture(path)\n",
    "#     while(cap.isOpened()):\n",
    "#         if frame == 300:\n",
    "#             break\n",
    "#         ret, img = cap.read()\n",
    "#         if ret == False:\n",
    "#             break\n",
    "        \n",
    "#         # 처음이면\n",
    "#         if not before_face_img_coord:\n",
    "#             face = mtcnn.detect_faces(img)\n",
    "#             # 처음인데 얼굴이 없으면 0.5로\n",
    "#             if not face:\n",
    "#                 break\n",
    "#             x1,y1,w,h = face['box']\n",
    "#             x2 = min(x1+w, img.shape[1])\n",
    "#             y2 = min(y1+h, img.shape[0])\n",
    "#             x1 = max(x1, 0)\n",
    "#             y1 = max(y1, 0)\n",
    "#             crop_img = img[y1:y2, x1:x2]\n",
    "#             crop_img = cv2.resize(crop_img, (299, 299))\n",
    "#             np.append(face_images, crop_img)\n",
    "#             before_face_img_coord = [y1,y2,x1,x2]\n",
    "                \n",
    "#         # 이전에 얼굴을 검출했으면 그주변에서 검색\n",
    "#         else:\n",
    "#             im = image[max(before_face_img_coord[0]-200,0) : min(before_face_img_coord[1]+200,img.shape[0]),\n",
    "#                         max(before_face_img_coord[2]-200,0) : min(before_face_img_coord[3]+200,img.shape[1])]\n",
    "#             face = mtcnn.detect_faces(im)\n",
    "#             if face:\n",
    "#                 x11,y11,w,h = face[0]['box']\n",
    "#                 x1 = max(max(coord[2]-200, 0) + x11, 0)\n",
    "#                 x2 = min(x1 + w, img.shape[1])\n",
    "#                 y1 = max(max(coord[0]-200, 0) + y11, 0)\n",
    "#                 y2 = min(y1 + h, img.shape[0])\n",
    "#                 crop_img = img[y1:y2, x1:x2]\n",
    "#                 crop_img = cv2.resize(crop_img, (299, 299))\n",
    "#                 np.append(face_images, crop_img)\n",
    "#                 before_face_img_coord=[y1,y2,x1,x2]\n",
    "            \n",
    "#             # 검색 안됐으면 그전 사진으로\n",
    "#             else:\n",
    "#                 crop_img = img[before_face_img_coord[0]:before_face_img_coord[1],\n",
    "#                                before_face_img_coord[2]:before_face_img_coord[3]]\n",
    "#                 np.append(face_images, crop_img)\n",
    "#         frame += 1\n",
    "\n",
    "#     print(face_images.shape) # must be (1, 300, 299, 299, 3)\n",
    "#     if face_images:\n",
    "#         pred = model.predict(face_images)\n",
    "#     else:\n",
    "#         pred = 0\n",
    "#     filename.append(vid_name)\n",
    "#     label.append(pred)\n",
    "    \n",
    "#     print('*',end='')\n",
    "#     if (vid_num+1) % 50 == 49:\n",
    "#         print(vid_num,'/',all_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'filename': filename, 'label': label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission.loc[my_submission['label']==1,'label'] = 0.95\n",
    "my_submission.loc[my_submission['label']==0,'label'] = 0.05\n",
    "my_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
