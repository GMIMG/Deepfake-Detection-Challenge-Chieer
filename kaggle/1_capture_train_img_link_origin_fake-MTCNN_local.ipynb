{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageChops, ImageEnhance, ImageDraw\n",
    "from mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aagfhgtpmv.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>vudstovrck.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aapnvogymq.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>jdubbvfswz.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abarnvbtwb.mp4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>train</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abofeumbvv.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>atvmxvwyns.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abqwwspghj.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>qzimuostzz.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>etejaapnxh.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>wtreibcmgm.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>etmcruaihe.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>afoovlsmtx.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>etohcvnzbj.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>bdnaqemxmr.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eudeqjhdfd.mp4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>train</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eukvucdetx.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>gjypopglvi.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               label  split        original\n",
       "aagfhgtpmv.mp4  FAKE  train  vudstovrck.mp4\n",
       "aapnvogymq.mp4  FAKE  train  jdubbvfswz.mp4\n",
       "abarnvbtwb.mp4  REAL  train            None\n",
       "abofeumbvv.mp4  FAKE  train  atvmxvwyns.mp4\n",
       "abqwwspghj.mp4  FAKE  train  qzimuostzz.mp4\n",
       "...              ...    ...             ...\n",
       "etejaapnxh.mp4  FAKE  train  wtreibcmgm.mp4\n",
       "etmcruaihe.mp4  FAKE  train  afoovlsmtx.mp4\n",
       "etohcvnzbj.mp4  FAKE  train  bdnaqemxmr.mp4\n",
       "eudeqjhdfd.mp4  REAL  train            None\n",
       "eukvucdetx.mp4  FAKE  train  gjypopglvi.mp4\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample_metadata = pd.read_json('../input/deepfake-detection-challenge/train_sample_videos/metadata.json').T\n",
    "train_sample_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                 FAKE\n",
       "split                train\n",
       "original    bdnaqemxmr.mp4\n",
       "Name: etohcvnzbj.mp4, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample_metadata.loc['etohcvnzbj.mp4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 영상 path\n",
    "train_sample = '../input/deepfake-detection-challenge/train_sample_videos/'\n",
    "train_video_files = [train_sample + x for x in sorted(os.listdir(train_sample))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../input/deepfake-detection-challenge/train_sample_videos/metadata.json'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_video_files.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original이 있는 FAKE\n",
    "train_sample_metadata['FAKE has original'] = [(train_sample_metadata.iloc[:,2][i] in list(train_sample_metadata.index)) for i in train_sample_metadata.T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original이 있는 FAKE 수\n",
    "len(train_sample_metadata[train_sample_metadata['FAKE has original']]['original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FAKE가 있는 origin 수\n",
    "len(train_sample_metadata[train_sample_metadata['FAKE has original']]['original'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "atvmxvwyns.mp4    6\n",
       "meawmsgiti.mp4    6\n",
       "qeumxirsme.mp4    5\n",
       "kgbkktcjxf.mp4    5\n",
       "gbqrgajyca.mp4    4\n",
       "                 ..\n",
       "ixuouyigxa.mp4    1\n",
       "qokxxuayqn.mp4    1\n",
       "sunqwnmlkx.mp4    1\n",
       "qjlhemtkxk.mp4    1\n",
       "proiippuup.mp4    1\n",
       "Name: original, Length: 209, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample_metadata['original'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['atvmxvwyns.mp4', 'ccfoszqabv.mp4', 'dlpoieqvfb.mp4',\n",
       "       'aytzyidmgs.mp4', 'dkuayagnmc.mp4', 'bzythlfnhq.mp4',\n",
       "       'cppdvdejkc.mp4', 'bulkxhhknf.mp4', 'edyncaijwx.mp4',\n",
       "       'dzyuwjkjui.mp4', 'efwfxwwlbw.mp4', 'cprhtltsjp.mp4',\n",
       "       'djxdyjopjd.mp4', 'cpjxareypw.mp4', 'dbtbbhakdv.mp4',\n",
       "       'ellavthztb.mp4', 'bxzakyopjf.mp4', 'cizlkenljw.mp4',\n",
       "       'brwrlczjvi.mp4', 'drcyabprvt.mp4', 'crezycjqyk.mp4',\n",
       "       'cyxlcuyznd.mp4', 'ekcrtigpab.mp4', 'ehtdtkmmli.mp4',\n",
       "       'bwipwzzxxu.mp4', 'atkdltyyen.mp4', 'chtapglbcj.mp4',\n",
       "       'caifxvsozs.mp4', 'bffwsjxghk.mp4', 'duycddgtrl.mp4',\n",
       "       'ehccixxzoe.mp4', 'eckvhdusax.mp4', 'dakiztgtnw.mp4',\n",
       "       'bgwmmujlmc.mp4', 'abarnvbtwb.mp4', 'bejhvclboh.mp4',\n",
       "       'avmjormvsx.mp4', 'egghxjjmfg.mp4', 'dbnygxtwek.mp4',\n",
       "       'cmbzllswnl.mp4', 'afoovlsmtx.mp4', 'bdnaqemxmr.mp4'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FAKE가 있는 origin 영상 리스트\n",
    "original_vidio_has_fake = train_sample_metadata[train_sample_metadata['FAKE has original']]['original'].unique()\n",
    "original_vidio_has_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# path\n",
    "original_vidio_has_fake_path = '../input/deepfake-detection-challenge/train_sample_videos/' + original_vidio_has_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['abofeumbvv.mp4', 'bqkdbcqjvb.mp4', 'cdyakrxkia.mp4', 'cycacemkmt.mp4',\n",
       "       'czmqpxrqoh.mp4', 'dakqwktlbi.mp4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0번 origin 영상으로 만든 fake 영상들 => 6개\n",
    "train_sample_metadata[train_sample_metadata['original']==original_vidio_has_fake[0]].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 만들어주기 (kaggle kernel에서 필요)\n",
    "try:\n",
    "    os.makedirs('../working/dataset/FAKE3')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.makedirs('../working/dataset/REAL3')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/42\n",
      "1/42\n",
      "2/42\n",
      "3/42\n",
      "4/42\n",
      "5/42\n",
      "6/42\n",
      "7/42\n",
      "8/42\n",
      "9/42\n",
      "10/42\n",
      "11/42\n",
      "12/42\n",
      "13/42\n",
      "14/42\n",
      "15/42\n",
      "16/42\n",
      "17/42\n",
      "18/42\n",
      "19/42\n",
      "20/42\n",
      "21/42\n",
      "22/42\n",
      "23/42\n",
      "24/42\n",
      "25/42\n",
      "26/42\n",
      "27/42\n",
      "28/42\n",
      "29/42\n",
      "30/42\n",
      "31/42\n",
      "32/42\n",
      "33/42\n",
      "34/42\n",
      "35/42\n",
      "36/42\n",
      "37/42\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4045: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-dcbcb9f3adef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     70\u001b[0m                     \u001b[1;31m#plt.imshow(crop_img2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                     \u001b[1;31m#plt.show()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m                     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'../working/dataset/REAL3/REAL_{file_name}_{frame}_{face_idx}.jpg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrop_img2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m299\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m299\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m                     \u001b[0mcrop_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrop_img2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4045: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "# origin 영상들로 학습시작\n",
    "#detector = dlib.get_frontal_face_detector()\n",
    "train_video_files = sorted(original_vidio_has_fake)\n",
    "\n",
    "#train_video_files = ['bdnaqemxmr.mp4']\n",
    "\n",
    "vid_num = 0\n",
    "all_vid = len(train_video_files)\n",
    "# origin 영상 얼굴찾기\n",
    "for vid in train_video_files:\n",
    "    count = 0\n",
    "    path = '../input/deepfake-detection-challenge/train_sample_videos/' + vid\n",
    "    file_name = vid.split('.')[0]\n",
    "    face_coord = {}\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frame = 0\n",
    "    mtcnn = MTCNN() # device='cuda:0',\n",
    "    \n",
    "    before_face_img_coord = []\n",
    "    \n",
    "    while(cap.isOpened()):\n",
    "        ret = cap.grab()\n",
    "        if ret == False:\n",
    "            break\n",
    "        #if frame % 30 == 0:\n",
    "        ret, image = cap.retrieve()\n",
    "        #img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        img = image\n",
    "        face_coord[frame]=[]\n",
    "        # 처음 얼굴이 나오면\n",
    "        if not before_face_img_coord:\n",
    "            faces = mtcnn.detect_faces(img)\n",
    "            # 얼굴 한개 이상?\n",
    "            for face_idx, face in enumerate(faces):\n",
    "                if 'confidence' in face and face['confidence'] > 0.9:\n",
    "                    x1,y1,w,h = face['box']\n",
    "                    x2 = min(x1+w, img.shape[1])\n",
    "                    y2 = min(y1+h, img.shape[0])\n",
    "                    x1 = max(x1, 0)\n",
    "                    y1 = max(y1, 0)\n",
    "                    crop_img = img[y1:y2, x1:x2]\n",
    "                    face_coord[frame].append([y1,y2,x1,x2])\n",
    "\n",
    "                    #plt.imshow(crop_img)\n",
    "                    #plt.show()\n",
    "                    cv2.imwrite(f'../working/dataset/REAL3/REAL_{file_name}_{frame}_{face_idx}.jpg', cv2.resize(crop_img, (299, 299)))\n",
    "                    before_face_img_coord.append([y1,y2,x1,x2])\n",
    "                    \n",
    "                    break\n",
    "                    \n",
    "        # 이전에 검출된 face가 있으면\n",
    "        else:\n",
    "            for face_idx, coord in enumerate(before_face_img_coord):\n",
    "                im = img[max(coord[0]-100,0) : min(coord[1]+100,img.shape[0]),\n",
    "                         max(coord[2]-100,0) : min(coord[3]+100,img.shape[1])]\n",
    "                face = mtcnn.detect_faces(im)\n",
    "                if face:\n",
    "                    # 1개만 저장해\n",
    "                    x11,y11,w,h = face[0]['box']\n",
    "                    x1 = max(coord[2]-100 + x11, 0)\n",
    "                    x2 = min(x1 + w, img.shape[1])\n",
    "                    y1 = max(coord[0]-100 + y11, 0)\n",
    "                    y2 = min(y1 + h, img.shape[0])\n",
    "                    crop_img2 = img[y1:y2, x1:x2]\n",
    "                    \n",
    "                    \n",
    "                    face_coord[frame].append([y1,y2,x1,x2])\n",
    "                    before_face_img_coord[face_idx]=[y1,y2,x1,x2]\n",
    "                    \n",
    "                    #plt.imshow(crop_img2)\n",
    "                    #plt.show()\n",
    "                    cv2.imwrite(f'../working/dataset/REAL3/REAL_{file_name}_{frame}_{face_idx}.jpg', cv2.resize(crop_img2, (299, 299)))\n",
    "                    crop_img = crop_img2\n",
    "                else:\n",
    "                    face_coord[frame].append([y1,y2,x1,x2])\n",
    "                    cv2.imwrite(f'../working/dataset/REAL3/REAL_{file_name}_{frame}_{face_idx}.jpg', cv2.resize(crop_img, (299, 299)))\n",
    "\n",
    "        frame += 1\n",
    "    cap.release()\n",
    "    \n",
    "    # 이비디오의 fake 영상만큼 반복\n",
    "    for fake_vid in train_sample_metadata[train_sample_metadata['original']==vid].index:\n",
    "        fake_path = '../input/deepfake-detection-challenge/train_sample_videos/' + fake_vid\n",
    "        cap2 = cv2.VideoCapture(fake_path)\n",
    "        fake_vid_name = fake_vid.split('.')[0]\n",
    "        frame2 = 0\n",
    "        while(cap2.isOpened()):\n",
    "            ret2 = cap2.grab()\n",
    "            if ret2 == False:\n",
    "                break\n",
    "            #if frame2 % 30 == 0:\n",
    "            ret2, image2 = cap2.retrieve()\n",
    "            #img2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n",
    "            for face_idx, i in enumerate(face_coord[frame2]):\n",
    "                y1,y2,x1,x2 = i\n",
    "                crop_img3 = image2[y1:y2, x1:x2]\n",
    "                cv2.imwrite(f'../working/dataset/FAKE3/FAKE_{fake_vid_name}_{frame2}_{face_idx}_{file_name}.jpg', cv2.resize(crop_img3, (299, 299)))\n",
    "            frame2 += 1\n",
    "        cap2.release()\n",
    "\n",
    "        \n",
    "    print(f'{vid_num}/{all_vid}')\n",
    "    vid_num += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1297"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coord[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coord[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
