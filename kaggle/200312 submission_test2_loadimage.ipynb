{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        # print(os.path.join(dirname, filename))\n",
    "        pass\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#!pip install '../input/dlibpkg/dlib-19.19.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install '../input/face-recognition/click-7.1.1-py2.py3-none-any.whl'\n",
    "#!pip install '/kaggle/input/face-recognition/Pillow-7.0.0-cp38-cp38-win32.whl'\n",
    "#!pip install '../input/needwheels/face_recognition_models-0.3.0-py2.py3-none-any.whl'\n",
    "#!pip install '../input/needwheels/face_recognition-1.3.0-py2.py3-none-any.whl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageChops, ImageEnhance, ImageDraw\n",
    "import face_recognition\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = '../input/deepfake-detection-challenge/test_videos/'\n",
    "test_video_files = [test + x for x in sorted(os.listdir(test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs('../working/dataset/TEST')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_video_files = sorted(test_video_files)\n",
    "test_image_path = '../working/dataset/TEST/'\n",
    "test_image_files = [test_image_path + x for x in sorted(os.listdir(test_image_path))]\n",
    "\n",
    "test_videos = '../input/deepfake-detection-challenge/test_videos/'\n",
    "test_movie_files = [test_videos + x for x in sorted(os.listdir(test_videos))]\n",
    "\n",
    "dic = {i.split('/')[-1]:[0,0] for i in test_movie_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 128, 128, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 128, 128, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "xception (Model)                (None, 2)            20865578    lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Concatenate)       (None, 2)            0           xception[1][0]                   \n",
      "                                                                 xception[2][0]                   \n",
      "==================================================================================================\n",
      "Total params: 20,865,578\n",
      "Trainable params: 20,811,050\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('deepfake-detection-model-xception.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_resnet_v2 (Model)  (None, 2, 2, 1536)        54336736  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 3074      \n",
      "=================================================================\n",
      "Total params: 54,339,810\n",
      "Trainable params: 54,279,266\n",
      "Non-trainable params: 60,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('../input/kerasmodel/deepfake-detection-model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_path = '../working/dataset/TEST/'\n",
    "test_images = [test_images_path + x for x in sorted(os.listdir(test_images_path))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../working/dataset/TEST/aassnaulhq_0.jpg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as pilimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aassnaulhq.mp4'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aassnaulhq.mp4 : 0.46\n",
      "6/2853\n",
      "aayfryxljh.mp4 : 0.00\n",
      "16/2853\n",
      "acazlolrpz.mp4 : 0.03\n",
      "24/2853\n",
      "adohdulfwb.mp4 : 0.12\n",
      "34/2853\n",
      "ahjnxtiamx.mp4 : 0.00\n",
      "44/2853\n",
      "ajiyrjfyzp.mp4 : 0.15\n",
      "55/2853\n",
      "aktnlyqpah.mp4 : 0.00\n",
      "65/2853\n",
      "alrtntfxtd.mp4 : 0.43\n",
      "68/2853\n",
      "aomqqjipcp.mp4 : 0.42\n",
      "78/2853\n",
      "apedduehoy.mp4 : 0.40\n",
      "88/2853\n",
      "apvzjkvnwn.mp4 : 0.12\n",
      "98/2853\n",
      "axfhbpkdlc.mp4 : 0.07\n",
      "108/2853\n",
      "ayipraspbn.mp4 : 0.06\n",
      "118/2853\n",
      "bcbqxhziqz.mp4 : 0.02\n",
      "120/2853\n",
      "bcvheslzrq.mp4 : 0.12\n",
      "130/2853\n",
      "bdshuoldwx.mp4 : 0.19\n",
      "138/2853\n",
      "bfdopzvxbi.mp4 : 0.97\n",
      "139/2853\n",
      "bfjsthfhbd.mp4 : 0.00\n",
      "140/2853\n",
      "bkcyglmfci.mp4 : 0.01\n",
      "142/2853\n",
      "bktkwbcawi.mp4 : 0.00\n",
      "152/2853\n",
      "bkuzquigyt.mp4 : 0.00\n",
      "161/2853\n",
      "blszgmxkvu.mp4 : 0.47\n",
      "163/2853\n",
      "bnuwxhfahw.mp4 : 0.15\n",
      "164/2853\n",
      "bofrwgeyjo.mp4 : 0.35\n",
      "174/2853\n",
      "btdxnajogv.mp4 : 0.08\n",
      "184/2853\n",
      "bvpeerislp.mp4 : 0.00\n",
      "194/2853\n",
      "bwdmzwhdnw.mp4 : 0.00\n",
      "204/2853\n",
      "bzvzpwrabw.mp4 : 0.70\n",
      "209/2853\n",
      "cekarydqba.mp4 : 0.00\n",
      "219/2853\n",
      "cekwtyxdoo.mp4 : 0.28\n",
      "229/2853\n",
      "cjkctqqakb.mp4 : 0.15\n",
      "239/2853\n",
      "cnpanmywno.mp4 : 0.26\n",
      "246/2853\n",
      "cnxccbjlct.mp4 : 0.32\n",
      "256/2853\n",
      "coqwgzpbhx.mp4 : 0.32\n",
      "262/2853\n",
      "cosghhimnd.mp4 : 0.00\n",
      "270/2853\n",
      "coujjnypba.mp4 : 0.31\n",
      "272/2853\n",
      "cqxxumarvp.mp4 : 0.01\n",
      "281/2853\n",
      "csnkohqxdv.mp4 : 0.01\n",
      "291/2853\n",
      "cxsvvnxpyz.mp4 : 0.80\n",
      "292/2853\n",
      "czfqlbcfpa.mp4 : 0.25\n",
      "302/2853\n",
      "dcqodpzomd.mp4 : 0.01\n",
      "309/2853\n",
      "ddtbarpcgo.mp4 : 0.65\n",
      "314/2853\n",
      "demuhxssgl.mp4 : 0.16\n",
      "315/2853\n",
      "didzujjhtg.mp4 : 0.12\n",
      "325/2853\n",
      "dkuqbduxev.mp4 : 0.46\n",
      "327/2853\n",
      "dmmvuaikkv.mp4 : 0.01\n",
      "335/2853\n",
      "dnmowthjcj.mp4 : 0.18\n",
      "345/2853\n",
      "doniqevxeg.mp4 : 0.02\n",
      "355/2853\n",
      "dozjwhnedd.mp4 : 0.00\n",
      "365/2853\n",
      "dpevefkefv.mp4 : 0.26\n",
      "375/2853\n",
      "dpmgoiwhuf.mp4 : 0.20\n",
      "385/2853\n",
      "dsnxgrfdmd.mp4 : 0.18\n",
      "395/2853\n",
      "dtozwcapoa.mp4 : 0.02\n",
      "405/2853\n",
      "dvkdfhrpph.mp4 : 0.00\n",
      "414/2853\n",
      "dvtpwatuja.mp4 : 0.06\n",
      "422/2853\n",
      "dvwpvqdflx.mp4 : 0.00\n",
      "432/2853\n",
      "dxfdovivlw.mp4 : 0.14\n",
      "435/2853\n",
      "dxgnpnowgk.mp4 : 0.00\n",
      "445/2853\n",
      "dyjklprkoc.mp4 : 0.07\n",
      "448/2853\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-c136109cddde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mpix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.mp4'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m         callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;31m# Setup work for each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    910\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m     \u001b[0;34m\"\"\"Resets the state of metrics.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_training_eval_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_get_training_eval_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2862\u001b[0m       \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_loss_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2863\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'metrics'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2864\u001b[0;31m       \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2865\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mmetrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    412\u001b[0m       \u001b[0mmetrics\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_metric_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_metrics_from_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_get_metrics_from_layers\u001b[0;34m(layers)\u001b[0m\n\u001b[1;32m   3263\u001b[0m       \u001b[0;31m# include the metrics that were added in compile API of a nested model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3264\u001b[0m       \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3265\u001b[0;31m       \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_metrics_from_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3266\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3267\u001b[0m       \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_get_metrics_from_layers\u001b[0;34m(layers)\u001b[0m\n\u001b[1;32m   3265\u001b[0m       \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_metrics_from_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3266\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3267\u001b[0;31m       \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3268\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mmetrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1151\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gather_children_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'metrics'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_subclass_implementers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_gather_children_attribute\u001b[0;34m(self, attribute)\u001b[0m\n\u001b[1;32m   2336\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_layers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2337\u001b[0m       nested_layers = trackable_layer_utils.filter_empty_layer_containers(\n\u001b[0;32m-> 2338\u001b[0;31m           self._layers)\n\u001b[0m\u001b[1;32m   2339\u001b[0m       return list(\n\u001b[1;32m   2340\u001b[0m           itertools.chain.from_iterable(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/layer_utils.py\u001b[0m in \u001b[0;36mfilter_empty_layer_containers\u001b[0;34m(layer_list)\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0;34m\"\"\"Filter out empty Layer-like containers and uniquify.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0;31m# TODO(b/130381733): Make this an attribute in base_layer.Layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m   \u001b[0mexisting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentitySet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m   \u001b[0mto_visit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0mfiltered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/object_identity.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "old_name = test_images[0].split('/')[-1].split('_')[0]+'.mp4'\n",
    "test_videos = '../input/deepfake-detection-challenge/test_videos/'\n",
    "test_movie_files = [test_videos + x for x in sorted(os.listdir(test_videos))]\n",
    "dic = {i.split('/')[-1]:[0,0] for i in test_movie_files}\n",
    "count = 0\n",
    "for test_image in test_images:\n",
    "    \n",
    "    im = pilimg.open(test_image)\n",
    "    pix = np.array(im)\n",
    "    \n",
    "    #pil = Image.fromarray(crop_img)\n",
    "    #p = ImageDraw.Draw(pil)\n",
    "    #pix = np.array(cv2.resize(pix, (128, 128)))\n",
    "    #pix = pix[np.newaxis] # 차원 확장\n",
    "    \n",
    "    pix = (pix.flatten() / 255.0).reshape(-1, 128, 128, 3)\n",
    "    pred = model.predict(pix)[0]\n",
    "    file_name = test_image.split('/')[-1].split('_')[0]\n",
    "    filename = file_name+'.mp4'\n",
    "    dic[filename][0] += pred[1]\n",
    "    dic[filename][1] += 1\n",
    "\n",
    "\n",
    "    count += 1\n",
    "    if filename!=old_name:\n",
    "        print(f'{old_name} : {dic[old_name][0]/dic[old_name][1]:.2f}')\n",
    "        print(f'{count}/{len(test_images)}')\n",
    "    old_name = filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real</th>\n",
       "      <th>num_img</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aassnaulhq.mp4</th>\n",
       "      <td>3.622349</td>\n",
       "      <td>5</td>\n",
       "      <td>0.72447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aayfryxljh.mp4</th>\n",
       "      <td>7.244698</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acazlolrpz.mp4</th>\n",
       "      <td>5.795759</td>\n",
       "      <td>8</td>\n",
       "      <td>0.72447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adohdulfwb.mp4</th>\n",
       "      <td>7.244698</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ahjnxtiamx.mp4</th>\n",
       "      <td>7.244698</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ztyvglkcsf.mp4</th>\n",
       "      <td>7.244698</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuwwbbusgl.mp4</th>\n",
       "      <td>7.244698</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zxacihctqp.mp4</th>\n",
       "      <td>3.622349</td>\n",
       "      <td>5</td>\n",
       "      <td>0.72447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zyufpqvpyu.mp4</th>\n",
       "      <td>7.244698</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzmgnglanj.mp4</th>\n",
       "      <td>0.724470</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    real  num_img    label\n",
       "filename                                  \n",
       "aassnaulhq.mp4  3.622349        5  0.72447\n",
       "aayfryxljh.mp4  7.244698       10  0.72447\n",
       "acazlolrpz.mp4  5.795759        8  0.72447\n",
       "adohdulfwb.mp4  7.244698       10  0.72447\n",
       "ahjnxtiamx.mp4  7.244698       10  0.72447\n",
       "...                  ...      ...      ...\n",
       "ztyvglkcsf.mp4  7.244698       10  0.72447\n",
       "zuwwbbusgl.mp4  7.244698       10  0.72447\n",
       "zxacihctqp.mp4  3.622349        5  0.72447\n",
       "zyufpqvpyu.mp4  7.244698       10  0.72447\n",
       "zzmgnglanj.mp4  0.724470        1  0.72447\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(dic, orient='index',columns=['real', 'num_img'])\n",
    "df.index.name='filename'\n",
    "df['label'] = (df['real']/df['num_img']).fillna(0.5) # 평균내기 # 얼굴 인식 못한 사진은 0.5로\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aassnaulhq.mp4</th>\n",
       "      <td>0.004531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aayfryxljh.mp4</th>\n",
       "      <td>0.004531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acazlolrpz.mp4</th>\n",
       "      <td>0.004531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adohdulfwb.mp4</th>\n",
       "      <td>0.004531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ahjnxtiamx.mp4</th>\n",
       "      <td>0.004531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ztyvglkcsf.mp4</th>\n",
       "      <td>0.004531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuwwbbusgl.mp4</th>\n",
       "      <td>0.004531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zxacihctqp.mp4</th>\n",
       "      <td>0.004531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zyufpqvpyu.mp4</th>\n",
       "      <td>0.004531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzmgnglanj.mp4</th>\n",
       "      <td>0.004531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   label\n",
       "filename                \n",
       "aassnaulhq.mp4  0.004531\n",
       "aayfryxljh.mp4  0.004531\n",
       "acazlolrpz.mp4  0.004531\n",
       "adohdulfwb.mp4  0.004531\n",
       "ahjnxtiamx.mp4  0.004531\n",
       "...                  ...\n",
       "ztyvglkcsf.mp4  0.004531\n",
       "zuwwbbusgl.mp4  0.004531\n",
       "zxacihctqp.mp4  0.004531\n",
       "zyufpqvpyu.mp4  0.004531\n",
       "zzmgnglanj.mp4  0.004531\n",
       "\n",
       "[400 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df[['label']]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aassnaulhq.mp4</th>\n",
       "      <td>0.004531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aayfryxljh.mp4</th>\n",
       "      <td>0.004531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acazlolrpz.mp4</th>\n",
       "      <td>0.004531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adohdulfwb.mp4</th>\n",
       "      <td>0.004531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ahjnxtiamx.mp4</th>\n",
       "      <td>0.004531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ztyvglkcsf.mp4</th>\n",
       "      <td>0.004531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuwwbbusgl.mp4</th>\n",
       "      <td>0.004531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zxacihctqp.mp4</th>\n",
       "      <td>0.004531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zyufpqvpyu.mp4</th>\n",
       "      <td>0.004531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzmgnglanj.mp4</th>\n",
       "      <td>0.004531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   label\n",
       "filename                \n",
       "aassnaulhq.mp4  0.004531\n",
       "aayfryxljh.mp4  0.004531\n",
       "acazlolrpz.mp4  0.004531\n",
       "adohdulfwb.mp4  0.004531\n",
       "ahjnxtiamx.mp4  0.004531\n",
       "...                  ...\n",
       "ztyvglkcsf.mp4  0.004531\n",
       "zuwwbbusgl.mp4  0.004531\n",
       "zxacihctqp.mp4  0.004531\n",
       "zyufpqvpyu.mp4  0.004531\n",
       "zzmgnglanj.mp4  0.004531\n",
       "\n",
       "[400 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc[df2['label']==0] = 0.01\n",
    "df2.loc[df2['label']==1] = 0.09\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('submission_test.csv') # csv 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
