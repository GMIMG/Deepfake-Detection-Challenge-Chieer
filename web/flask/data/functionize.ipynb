{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, jsonify\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import preprocessing, models, backend as K\n",
    "import numpy as np\n",
    "import cv2\n",
    "from mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('deepfake-detection2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _make_execution_function.<locals>.distributed_function at 0x000001AEC76F5438> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _make_execution_function.<locals>.distributed_function at 0x000001AEC76F5438> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function _make_execution_function.<locals>.distributed_function at 0x000001AEC76F5438> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function _make_execution_function.<locals>.distributed_function at 0x000001AEC76F5438> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function _make_execution_function.<locals>.distributed_function at 0x000001AEC76F5438> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function _make_execution_function.<locals>.distributed_function at 0x000001AEC76F5438> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function _make_execution_function.<locals>.distributed_function at 0x000001AEC76F5438> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function _make_execution_function.<locals>.distributed_function at 0x000001AEC76F5438> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    }
   ],
   "source": [
    "input_shape = (160,160,3)\n",
    "mtcnn = MTCNN()\n",
    "# 영상 불러오기\n",
    "videos_path = 'test1.mp4'\n",
    "vid_name = videos_path.split('/')[-1].split('.')[0]\n",
    "# 프레임으로 나눠서 저장\n",
    "cap = cv2.VideoCapture(videos_path)\n",
    "frame = 0\n",
    "detect_face_num = 0\n",
    "\n",
    "#heat_images = []\n",
    "\n",
    "\n",
    "\n",
    "def get_face_coord(img):\n",
    "    # 얼굴 detect\n",
    "    face = mtcnn.detect_faces(img)\n",
    "    # 얼굴 없으면 다음 프레임\n",
    "    if not face:\n",
    "        return None\n",
    "    # 얼굴 위치\n",
    "    x1,y1,w,h = face[0]['box']\n",
    "    x2 = min(x1+w, img.shape[1])\n",
    "    y2 = min(y1+h, img.shape[0])\n",
    "    x1 = max(x1, 0)\n",
    "    y1 = max(y1, 0)\n",
    "    return [y1,y2,x1,x2]\n",
    "\n",
    "\n",
    "def crop_img(face_coord):\n",
    "    # 이미지 자르기\n",
    "    y1,y2,x1,x2 = face_coord\n",
    "    crop_img = img[y1:y2, x1:x2]\n",
    "    crop_img = cv2.resize(crop_img, (input_shape[0], input_shape[1]))\n",
    "    return crop_img\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def predict_and_generate_heatmap(model, img_tensor):\n",
    "    # 프레임 가져와서 히트맵 표시\n",
    "    conv_layer = model.get_layer(\"conv_7b\")\n",
    "    heatmap_model = models.Model([model.inputs], [conv_layer.output, model.output])\n",
    "    # # Get gradient of the winner class w.r.t. the output of the (last) conv. layer\n",
    "    with tf.GradientTape() as gtape:\n",
    "        conv_output, predictions = heatmap_model(img_tensor)\n",
    "        loss = predictions[:, tf.math.argmax(predictions[0])]\n",
    "        grads = gtape.gradient(loss, conv_output)\n",
    "        pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_output), axis=-1)\n",
    "    heatmap = tf.math.maximum(heatmap, 0)\n",
    "    \n",
    "    max_heat = tf.math.reduce_max(heatmap)\n",
    "#     if max_heat == 0:\n",
    "#         max_heat = 1e-10\n",
    "    heatmap /= max_heat\n",
    "    return heatmap, predictions[0][1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pred = 0\n",
    "while(cap.isOpened()):\n",
    "    if frame > 10 or detect_face_num > 5:\n",
    "        break\n",
    "\n",
    "    ret, img = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "\n",
    "    face_coord = get_face_coord(img)\n",
    "    if not face_coord:\n",
    "        continue\n",
    "    detect_face_num+=1\n",
    "\n",
    "    crop_image = crop_img(face_coord)\n",
    "\n",
    "    # 이미지 전처리 및 예측\n",
    "    img_tensor = (crop_image.flatten() / 255.0).reshape(-1, input_shape[0], input_shape[1], 3)\n",
    "\n",
    "    heatmap, predict = predict_and_generate_heatmap(model, img_tensor)\n",
    "    heatmap = np.array(heatmap)\n",
    "    heatmap2 = cv2.resize(heatmap, (img_tensor.shape[2], img_tensor.shape[1]))\n",
    "    heatmap2 = np.uint8(255 * heatmap2)\n",
    "    heatmap2 = cv2.applyColorMap(heatmap2, cv2.COLORMAP_JET)\n",
    "    hif = .5\n",
    "    superimposed_img = heatmap2 * hif + crop_image\n",
    "    \n",
    "    #heat_images.append(superimposed_img.tolist())\n",
    "    pred += predict\n",
    "\n",
    "    output = f'output_{vid_name}_{detect_face_num}.jpeg'\n",
    "    cv2.imwrite(output, superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
